#+TITLE: Procesos estocásticos
#+SUBTITLE:
#+AUTHOR: Ignacio Cordón Castillo
#+OPTIONS: toc:nil
#+LANGUAGE: es
#+STARTUP: indent
#+DATE:

#+latex_header: \usepackage{amsmath} 
#+latex_header: \usepackage{amsthm}
#+latex_header: \usepackage{mathabx}
#+latex_header: \newtheorem*{theorem}{Teorema}
#+latex_header: \newtheorem*{fact}{Proposición}
#+latex_header: \newtheorem*{corollary}{Corolario}
#+latex_header: \newtheorem*{lemma}{Proposición}
#+latex_header: \newtheorem*{definition}{Definición}
#+latex_header: \setlength{\parindent}{0pt}
#+latex_header: \setlength{\parskip}{1em}
#+latex_header: \usepackage{color}
#+latex_header: \newenvironment{wording}{\setlength{\parskip}{0pt}\rule{\textwidth}{0.5em}}{~\\\rule{\textwidth}{0.5em}}
#+latex_header: \everymath{\displaystyle}
#+latex_header: \usepackage[left=3.5cm, right=3cm, top=3cm]{geometry}
#+attr_latex: :float t :width 4cm
[[../by-nc-sa.png]]

* TODO [1/5]
+ [ ] Limpiar las demostraciones de condicionamiento
+ [ ] ¿Qué quiere decir medible finita?
+ [ ] Demostración de ii. en la página 15 de estocásticos
+ [X] Demostración de iii. en la página 15 de estocásticos
+ [ ] Demostración de iv. en la página 15 de estocásticos: condicionamiento por etapas.

Las igualdades entre probabilidades, esperanzas, etc cuando dan lugar a una variable aleatoria, las entendemos como igualdades casi seguramente, dado que la probabilidad es una medida.

* Teoría general de procesos estocásticos
** Repaso teoría de la medida y teoría de probabilidad
*** Espacio medible

Es una tupla $(\Omega, \mathcal{A})$ donde $\mathcal{A}$ es una $\sigma$ álgebra, esto es, es cerrada para uniones numerables y cerrada para complementarios.

De la definición de $\sigma$ álgebra se puede deducir que es cerrada para intersecciones numerables y que el vacío y el total están en ella.

Como caso particular de $\sigma$ álgebra, las finitas se llaman álgebras.

*** Aplicación y función medible.

Dados dos espacios medibles $(\Omega_1, \mathcal{A}_1)$ y $(\Omega_2, \mathcal{A}_2)$, una *aplicación medible* es una aplicación $f: \Omega_1 \rightarrow \Omega_2$ verificando que para todo $A_2 \in \mathcal{A}_2$ se tiene $f^{-1}(A_2) \in \mathcal{A}_1$.

Una *función medible finita* es una aplicación medible donde $\mathcal{A}_2$ es $\sigma$ álgebra de Borel, multidimensional o unidimensional.

#+begin_fact
Una función $f: (\Omega, \mathcal{A}) \rightarrow (\mathbb{R}^n, \mathbb{B}^n)$ es una función medible multidimensional sii $f_i, \forall i=1,\ldots n$ es función medible unidimensional, donde $f=(f_1, \ldots f_n)^T$
#+end_fact

*** $\sigma$ álgebra generada por una clase de conjuntos

Sea $\mathcal{D}$ clase de conjuntos. Se define $\sigma(\mathcal{D})$ como la menor $\sigma$ álgebra que contiene a $\mathcal{D}$.

#+begin_fact
Una función $f: (\Omega_1, \mathcal{A}_1) \rightarrow (\Omega_2, \mathcal{A}_2)$ entre espacios medibles es aplicación medible sii $f^{-1}(\mathcal{D}) \subseteq \mathcal{A}_1$ con $\mathcal{D} : \sigma(\mathcal{D}) = \mathcal{A}_2$
#+end_fact

*** $\sigma$ álgebra de Borel

Se define como $\mathbb{B}^n = \sigma(\{ ]-\infty, x], x \in \mathbb{R}^n\})$, donde $]-\infty,x] = ]-\infty, x_1] \times \ldots \times ]-\infty, x_n]$.

#+begin_fact
Una función $f:(\Omega, \mathcal{A}) \rightarrow (\mathbb{R}^n, \mathbb{B}^n)$ $f$ es medible sii $f^{-1}(]-\infty, x]) = [f\le x] \in \mathcal{A}$ para todo $x\in \mathbb{R}^n$
#+end_fact

*** Medida

Dado un espacio medible $(\Omega, \mathcal{A})$ una medida es una aplicación $\mu : \mathcal{A} \rightarrow \mathbb{R}$ verificando que es no negativa y es $\sigma$ aditiva.

A la terna $(\Omega, \mathcal{A}, \mu)$ se la llama *espacio de medida*.

#+begin_definition
*Axiomas de Kolmogorov*

Una medida $\mu$ sobre un espacio medible es probabilidad si además $\sigma(\Omega) = 1$. Los otros dos considerados axiomas de Kolmogorov son la no negatividad y $\sigma$ aditividad, ya incluidas en la definición de medida.

Si $\mu$ es probabilidad, el espacio de medida asociado se denomina *espacio probabilístico*.
#+end_definition
*** Variables aleatorias

$X: \mathcal{A} \rightarrow \mathbb{R}$ es una variable aleatoria sii es *función medible finita definida en un espacio probabilístico*. Esto implica que la función va de espacios $(\Omega, \mathcal{A})$ a $(\mathbb{R}, \mathbb{B})$

Si la función llega al espacio $(\mathbb{R}^n, \mathbb{B}^n)$ tenemos un vector aleatorio.

Se notará v.a. indistintamente a variables aleatorias y vectores aleatorios. Se infiere su significado por el contexto.

#+begin_fact
$X=(X_1, \ldots X_n)^T$ es vector aleatorio sii $X_i$ es v.a. para todo $i=1, \ldots n$
#+end_fact

#+begin_definition
Sea $X$ v.a. sobre $(\Omega, \mathcal{A}, P)$ se define:

+ *Distribución de la probabilidad* de $X$ como $P_X(B) = P[X \in B], \forall B \in \mathbb{B}$.
+ *Función de distribución* como $F_X(x) = P[X \le x]$
+ *Función característica* como $\varphi_X(t) = E[e^{itX}]$.
#+end_definition

#+begin_definition
Se define la *$\sigma$ álgebra generada* por $X$ como $\sigma(X):= X^{-1}(\mathbb{B}^n)$
#+end_definition

#+begin_definition
$X$ va es:

+ *discreta* sii $\exists E_x$ numerable verificando $P[X \in E_x] = 1$
+ *continua* sii $\exists f$ función de densidad tal que $F(x) = \int_{-\infty}^x f(y) dy$
#+end_definition

#+begin_definition
Se define:
+ *Momentos no centrados*: $E[X^k]$
+ *Momentos centrados*: $E[(X-a)^k]$

Como caso particular: $\sigma^2 = E[(X-E[X])^2] = EX^2 - (EX)^2$
#+end_definition


#+begin_definition
*Covarianza*

\[Cov(X,Y) = E[(X-EX)] E[(Y-EY)]\]
#+end_definition

** Procesos estocásticos
*Un proceso estocástico* (PE) es una familia $\{X_t\}_{t\in T}$ de v.a. definidas en $(\Omega, \mathcal{A}, P)$.

$T$ será un conjunto totalmente ordenado arbitrario, que se denomina *espacio paramétrico* (discreto/continuo).

En lo que sigue v.a. denotará variable aleatoria unidimensional.

Todos los $X_t$ verifican que van desde el espacio de medida $(\Omega, \mathcal{A}, P)$ hasta el espacio de estados $(E, \mathbb{B}_E)$, con $E \subseteq \mathbb{R}$.
#+begin_definition
*Trayectoria*

Dado un proceso estocástico $\{X_t\}_{t\in T}$ llamamos trayectoria asociada a un $\w \in \Omega$ fijo a la función $X (w)(t) := X_t (w)$ 
#+end_definition

#+begin_definition
*Proceso medible*

Un proceso se dice medible si la siguiente función es medible:

\[\begin{array}{rcl} 
T \times \Omega & \rightarrow & \mathbb{R}\\ 
(t,w) & \mapsto & X(w)(t) \end{array} \]
#+end_definition

*** Características de procesos estocásticos

Definimos, suponiendo que las esperanzas tienen siempre sentido:

**** Función media
$\mu : T \rightarrow \mathbb{R}$, con $\mu(t) = E(X_t)$
**** Momentos
$\mu_k : T \rightarrow \mathbb{R}$ con $\mu_k(t) = E[X_t^k]$
**** Función correlación
$R:T\times T \rightarrow \mathbb{R}$ con $R(t,s) = E[X_t X_s]$
**** Función covarianza
$C:T\times T \rightarrow \mathbb{R}$ con $C(t,s) = R(s,t) - \mu(t) \mu(s)$

** Clasificación de los procesos estocásticos
Sea $\{X_t\}_{t\in T}$ proceso estocástico con espacio de estados $(E, \mathbb{B}_E), E\subseteq \mathbb{R}$.

*** En función del espacio paramétrico:
- Si $T$ es discreto, tenemos PE en tiempo discreto
- si $T$ es continuo, tenemos PE en tiempo continuo

*** En función del espacio de estados:
- Si $E$ es discreto, tenemos PE discreto (cadenas)
- Si $E$ es continuo, tenemos PE continuo.


A los PDTC (procesos discretos en tiempo continuo), los llamamos cadenas de Markov.

*** Atendiendo a la relación entre las variables del proceso
+ *Incrementos independientes*: $X_{t_1}, X_{t_2}-X_{t_1}, \ldots, X_{t_n} - X_{t_{n-1}}$ son v.a. independientes.
+ *Incrementos estacionarios*: $\{X_t\}_{t\in T}$ es un proceso con incrementos estacionarios si $X_t - X_s$ y $X_{t+h}-X_{s+h}$ tienen la misma distribución $\forall h>0$
+ *Procesos estrictamente estacionarios* (estacionarios en sentido amplio): Para cualquier $n\in \mathbb{N}, h>0, \, \forall t_1, \, \ldots t_n, \, dist(X_{t_1}, \ldots X_{t_n}) = dist(X_{t_1 + h}, \ldots X_{t_n + h})$.
+ *Procesos débilmente estacionarios*: $\{X_t\}$ es de segundo orden ($E[X_t^2] < \infty \forall t$), $\mu(t)$ es contante y $C(s,t) := C(0,t-s)$


#+begin_fact
Todo proceso estrictamente estacionario con momentos de segundo orden es débilmente estacionario.
#+end_fact

*** Martingala
$\{X_n\}_{n\in \mathbb{N}}$ es *martingala* si $\forall n, \, EX_n < \infty, \, E[X_{n+1}/X_1, \ldots X_n] = X_n$ casi seguramente.
*** Procesos de Markov
$\{X_n\}_{n\in \mathbb{N}}$ es proceso de Markov sii $\forall n\in \mathbb{N}, \, \forall B \in \mathbb{B}$
\[P[X_{n+1} \in B/ X_1, \ldots X_n] = P[X_{n+1} \in B/X_n] \quad cs\]

*** PETD
**** Trayectorias

$\forall w \in \Omega$ fijo llamamos trayectoria en $w$ a $X(w): \mathbb{N} \rightarrow \mathbb{R}$ con $X(w)(n) = X_n(w) \in \mathbb{R}^{\mathbb{N}}$

Por tanto podemos definir la *función de trayectorias* como:

\[\begin{array}{rccl}
\mathcal{X}: & \Omega & \rightarrow & \mathbb{R}^{\mathbb{N}}\\
& w & \mapsto & \{X_n(w)\}_n
\end{array}\]

Para ver que $\mathcal{X}$ es medible nos hace falta una $\sigma$ álgebra sobre $\mathbb{R}^{\mathbb{N}}$.

#+begin_definition
Definimos el rectángulo de lados $B_1, \ldots B_k \in \mathbb{B}$ como:

\[R(B_1, \ldots B_k) = \Big\{ \{x_n\}_{n\in\mathbb{N}} : x_i \in B_i, i=1,\ldots k\Big\}\]

La clase de rectángulos medibles $\mathcal{C}^{\mathbb{N}}$ es semiálgebra (cerrado para el total y el vacío, para intersecciones, y verifica que para $A \in \mathcal{C}^{\mathbb{N}}$ existen $S_1, \ldots S_k$ disjuntos verificándose $\bar{A} = \bigcup_{j=1}^k S_j$)
#+end_definition

#+begin_definition
Definimos la $\sigma$ álgebra $\mathbb{B}^{\mathbb{N}} := \sigma(\mathcal{C}^{\mathbb{N}})$
#+end_definition

Usando que $\sigma(\mathcal{C}^{\mathbb{N}})$ es semiálgebra, la $\sigma$ álgebra se forma a partir de uniones finitas de elementos de $\mathcal{C}^{\mathbb{N}}$

#+begin_theorem
*Teorema de medibilidad - caracterización de PETD*

\[\{X_n\}_{n\in \mathbb{N}} \quad PETD \Leftrightarrow \mathcal{X}^{-1}(C), \, \forall C\in \mathcal{C}^{\mathbb{N}}\]
#+end_theorem
**** Distribución de $\{X_n\}_{n\in \mathbb{N}}$ PETD

Dado $\{X_n\}_{n\in \mathbb{N}}$ PETD definimos la medida de probabilidad:

\[P_{\mathcal{X}}: \mathbb{B}^{\mathbb{N}} \rightarrow [0,1], \quad P_{\mathcal{X}}(B) = P(\mathcal{X}^{-1}(B))\]

#+begin_theorem
*Teorema de consistencia de Kolmogorov*

$\forall n \in \mathbb{N}$ sea $P_n$ probabilidad en $(\mathbb{R}^n, \mathbb{B}^n)$ verificando $P_n(B_1 \times \ldots \times B_n) = P_{n+1}(B_1 \times \ldots B_n \times \mathbb{R})$ para cualesquiera $B_i \in \mathbb{B}$. Bajo dichas hipótesis se verifica que existe una única $\widehat{P}$ en $(\mathbb{R}^n, \mathbb{B}^n)$ tal que:

\[\widehat{P}(\left\{\{x_k\}_{k\in \mathbb{N}} : x_1 \in B_1, \ldots x_n \in B_n\right\}) = P_n(B_1 \times \ldots \times B_n)\]
#+end_theorem

#+begin_corollary
La distribución $P_{\mathcal{X}}$ del PETD $\{X_n\}_{n\in \mathbb{N}}$ viene determinada por las distriuciones finito dimensionales $dist(X_1, \ldots X_n)$
#+end_corollary

*** PETC
Tenemos el espacio de medida $(\Omega, \mathcal{A}, P)$ y $T\subseteq \mathbb{R}$ espacio paramétrico. Nuestro espacio de estados es $(E, \mathbb{B}_E)= (\mathbb{R}, \mathbb{B})$ con $E\subseteq \mathbb{R}$.

**** Trayectorias

$\forall w \in \Omega$ fijo llamamos trayectoria en $w$ a $X(w): T \rightarrow \mathbb{R}$ con $X(w)(t) = X_t(w) \in \mathbb{R}^T$

Por tanto podemos definir la función de trayectorias como:

\[\begin{array}{rccl}
\mathcal{X}: & \Omega & \rightarrow & \mathbb{R}^T\\
& w & \mapsto & \{X_t(w)\}_{t\in T}
\end{array}\]

Para ver que $\mathcal{X}$ es medible nos hace falta una $\sigma$ álgebra sobre $\mathbb{R}^T$.

#+begin_definition
Definimos el rectángulo de lados $B_1, \ldots B_k \in \mathbb{B}$ como:

\[R_{t_1, \ldots t_k}(B_1, \ldots B_k) = \Big\{ f:T \rightarrow \mathbb{R} : f(t_i) \in B_i, i=1,\ldots k\Big\}\]

La clase de rectángulos medibles $\mathcal{C}^T$ es semiálgebra.
#+end_definition

#+begin_definition
Definimos $\sigma$ álgebra $\mathbb{B}^T := \sigma(\mathcal{C}^T)$
#+end_definition

#+begin_fact
*Caracterización de $\mathbb{B}^T$*

$B\in \mathbb{B}^T \Leftrightarrow \exists D\in \mathbb{B}^{\mathbb{N}}, \{t_n\}_{n\in \mathbb{N}} \subseteq T$ tales que $B = \{f \in \mathbb{R}^T: \{f(t_n)\}_{n\in\mathbb{N}} \in D\}$
#+end_fact

#+begin_theorem
*Teorema de medibilidad - caracterización de PETC*

\[\{X_t\}_{t\in T} \quad PETC \Leftrightarrow \mathcal{X}^{-1}(C), \forall C\in \mathcal{C}^T\]
#+end_theorem

**** Distribución de $\{X_n\}_T$ PETC

Dado $\{X_t\}_{t \in T}$ PETC definimos la medida de probabilidad:

\[P_{\mathcal{X}}: \mathbb{B}^T \rightarrow [0,1], \quad P_{\mathcal{X}}(B) = P(\mathcal{X}^{-1}(B))\]

#+begin_theorem
*Extensión del teorema de consistencia de Kolmogorov*

Si $\forall n \in \mathbb{N}$, para todo $t_1, \ldots t_n$, $t_i < t_{i+1}$ tenemos $P_{t_1, \ldots t_n$ es probabilidad en $(\mathbb{R}^n, \mathbb{B}^n)$ verificando $P_{t_1, \ldots t_n} (B_1 \times \ldots \times B_n) = P_{t_1 \ldots t_{n+1}}(B_1 \times \ldots \times B_n \times \mathbb{R})$ entonces $\exists_1 \widehat{P}$ en $(\mathbb{R}^T, \mathbb{B}^T)$ verificando que $\forall t_1 < \ldots < t_n, t_i \in T, \quad \forall B_i \in \mathbb{B}$:

\[\widehat{P}(\left\{f\in \mathbb{R}^T : f(t_i) \in B_i, i=1, \ldots n \right\}) = P_{t_1, \ldots t_n}(B_1, \times B_n)\]
#+end_theorem
*** Procesos equivalentes
Sean $\{X_t\}_{t \in T}$, $\{Y_t\}_{t\in T}$

#+begin_definition 
Sean $\{X_t\}_{t\in T}$ y $\{Y_t\}_{t \in T}$, definidos sobre $(\Omega, \mathcal{A}, P)$. Se dicen:

1. *Equivalentes en sentido amplio* sii \[P_{\mathcal{X}} = P_{\mahtcal{Y}}\] Esta definición también puede extenderse a procesos definidos sobre distintos espacios de medida.
2. *Procesos equivalentes* sii $P[X_t = Y_t] = 1, \forall t \in T$. 
3. *Indistinguibles* sii $P(\bigcap_{t\in T} [X_t = Y_t]) = 1$.
#+end_definition

#+begin_fact
$3 \implies 2 \implies 1$ en la anterior definición. Los reversos de las implicaciones no son ciertos. 
#+end_fact

** Condicionamiento
Dado un espacio probabilístico $(\Omega, \mathcal{A}, P)$, $B,A \in \mathcal{A}$. Sea $\mathcal{D} \subseteq \mathcal{A}$ otra $\sigma$ álgebra y $X$ variable aleatoria con $EX < \infty$. 

#+begin_definition
*Probabilidad condicionada*

$P(\cdot/B): \mathcal{A} \rightarrow [0,1]$ definida por $P(A/B) = P(A\cap B)$ es función de probabilidad condicionada a $B$.
Además $(\Omega, \mathcal{A}, P(\cdot/B))$ es espacio de probabilidad.
#+end_definition

#+begin_definition
*Esperanza condicionada a un hecho*

Se define la esperanza condicionada de $X$ a $B$ como:

\[E[X/B] = \int_{\Omega} X dP(\cdot/B) = \frac{E[X1_B]}{P(B)}\]

En particular $E[1_A/B] = P(A/B)$
#+end_definition

#+begin_definition
*Esperanza condicionada a una $\sigma$ álgebra*

Se define $E[X/\mathcal{D}]$ como la única función cs($P_{\mathcal{D}}$), $\mathcal{D}$ medible que verifica:

\[\int_D E[X/\mathcal{D}] dP_{\mathcal{D}} = \int_D X dP \quad \forall D \in \mathcal{D}\]
#+end_definition

#+begin_definition
*Probabilidad condicionada a una $\sigma$ álgebra*

Se define $P(A/\mathcal{D}) = E[1_A/\mathcal{D}]$ para todo $A\in \mathcal{A}$.

Esta función cumple que es $\mathcal{D}$ medible, variable aletoria y que $E[P(A/\mathcal{D})] = P(A)$
#+end_definition

#+begin_definition
*Esperanza y probabilidad condicionadas a una variable aleatoria*

Dada $Y$ variable aleatoria integrable, se definen:

1. $E[X/Y] = E[X/\sigma(Y)]$
2. $P(A/Y) = P(A/\sigma(Y)) = E[1_A/\sigma(Y)]$
#+end_definition

#+begin_fact
*Propiedades del condicionamiento*

1. $X=c, cs(P)$ entonces $E[X/\mathcal{D}]=c, cs(P_{\mathcal{D}})$
2. Linealidad: $E[aX + bY/\mathcal{D}] = aE[X/\mathcal{D}] + bE[Y/\mathcal{D}]$
3. $X \ge Y, cs(P)$ entonces $E[X/\mathcal{D}] \ge E[Y/\mathcal{D}], cs(P_{\mathcal{D})$
4. $X$ es $\mathcal{D}$ medible, entonces $E[X/\mathcal{D}] = X, cs(P_{\mathcal{D}})$
5. $X$ es $\mathcal{D}$ medible, $X, Y, XY$ integrables, entonces $E[XY/\mathcal{D}] = XE[Y/\mathcal{D}]$
6. Si $X$ es independiente de $\mathcal{D}$ entonces $E[X/\mathcal{D}] = E[X], cs(P_{\mathcal{D}})$
7. Sea $\mathcal{D}_1 \subseteq \mathcal{D}_2 \subseteq \mathcal{D}$ $\sigma$ álgebras. Entonces: \[E[X/\mathcal{D}_1] = E[E[X/\mathcal{D}_1]/\mathcal{D}_2] = E[E[X/\mathcal{D}_2]/\mathcal{D}_1], cs(P_{\mathcal{D}})\]
#+end_fact

* Tema 3: Procesos de Markov
** Procesos de Markov en tiempo discreto
Suponemos en lo que sigue un espacio de medida $(\Omega, \mathcal{A}, P)$, un espacio paramétrico $T= \mathbb{N} \cup \{0\}$, $(E,\mathcal{B}_E)$ espacio paramétrico con $E\subseteq \mathbb{R}$ y $\{X_n\}_{n\ge 0}$ PETD.

#+begin_definition
*Filtración de $\sigma$ álgebras*

Se define una filtración de $\sigma$ álgebras como $\{\mathcal{F}_n\}_{n\ge 0}$  donde $\mathcal{F}_n$ es $\sigma$ álgebra para $n \in \mathbb{N}$ arbitrario y $\mathcal{F}_n \subseteq \mathcal{F}_{n+1}$.
#+end_definition

A la filtración dada por $\sigma_n = \sigma(X_0, \ldots X_n)$ se le llama *filtración natural asociada al proceso $\{X_n\}$*

*** Procesos de Markov respecto de una filtración de $\sigma$ álgebras arbitraria
#+begin_definition
$\{X_n\}$ es proceso de Markov respecto de la filtración $\{\mathcal{F}_n\}$ sii:

1. El proceso está adaptado a la $\sigma$ álgebra: $X_n^{-1} (\mathcal{B}_E) \subseteq \mathcal{F}_n$. Esto implica $\sigma(X_1, \ldots X_n) \subseteq \mathcal{F}_n$
2. $\forall B\in \mathcal{B}_E$, $\forall n \ge 1$ se tiene $P[X_n \in B / \mathcal{F}_{n-1}] = P[X_n \in B/X_{n-1}]$
#+end_definition


#+begin_fact
La segunda condición de la anterior definición equivale a decir que para toda $f: (E, \mathcal{B}_E) \longrightarrow (\mathbb{R}, \mathcal{B})$ medible y acotada, $\forall n \ge 1$ se verifica:

\[E[f(X_n) / \mathcal{F}_{n-1}] = E[f(X_n) / X_{n-1}]\]
#+end_fact

*** Procesos de Markov respecto de la filtración natural
La definición se extrae de la definición para filtración arbitraria sustituyendo $\{\mathcal{F}_n\}$ por la filtración natural $\{\sigma_n\}$, con la salvedad de que el primer punto de la definición ya se cumple por definición de filtración natural. A los procesos de Markov respecto de la filtración natural lo llamaremos simplemente proceso de Markov.

Encontramos aparte de la caracterización dada para filtraciones arbitrarias, dos caracterizaciones más en el caso de PM respecto de la filtración natural.

#+begin_fact
Equivalen:

1. $\{X_n\}$ es de Markov
2. $\forall f:E \rightarrow \mathbb{R}$ medible y acotada, para todo $n_1 < \ldots < n_k$ se tiene \[E[f(X_n) / X_{n_1}, \ldots X_{n_k}] = E[f(X_n)/X_{n_k}]\]
3. $\forall B \in \mathcal{B}_E$, para todos $n_1 < \ldots < n_k < n$ se tiene: \[P[X_n \in B/X_{n_1}, \ldots X_{n_k}] = P[X_n \in B /X_{n_k}]\]
#+end_fact

#+begin_fact
*Ecuación de Chapman-Kolmogorov*

Sea $\{X_n\}$ proceso de Markov con $m \le k < n$. Dado $x\in E$, para todo $B\in \mathcal{B}_E$ se tiene:

\[P[X_n \in B/ X_m = x] = \int_E P[X_n \in B /X_k=y] P[X_k \in dy /X_m = x]\]
#+end_fact

*** Distribución de un proceso de Markov
Dado un PETD $\{X_n\}$ se tiene:

\[P[X_i \in B_i, i=0, \ldots n] = \prod_{i=1}^n P[X_i \in B_i/ X_{i-1} \in B_{i-1}] \cdot P[X_0 \in B_0]\]

Por tanto la distribución del proceso viene determinada por $dist(X_k/ X_{k-1}) \quad k=1, \ldots n$ y por $dist(X_0)$ o equivalentemente por $dist(X_{k-1}, X_{k}) \quad k=1, \ldots n$ y por $dist(X_k), \quad k=0,\ldots (n-1)$

*** Procesos de Markov homogéneos
Sea un PETD $\{X_n\}$. Es homogéneo cuando:

\[P[X_n\in B/X_{n-1}=x] = P[X_1 \in B / X_0=x] = p(x,B), \quad \forall B\in \mathcal{B}_E, n\ge 1, x\in E\]

En lo que sigue suponemos $\{X_n\}$ un PETD homogéneo.

**** Función de transición en un paso
Definimos la función de transición como $p(x,B)$ en la igualdad anterior.
***** Propiedades de la función de transición
1. $\forall B \in \mathcal{B}_E$ fijo se tiene $P(\cdot, B): (E,\mathcal{B}_E) \rightarrow (\mathbb{R}, \mathcal{B})$ es medible.
2. $\forall x \in E$ fijo se tiene $P(x, \cdot): \mathcal{B}_E \rightarrow \mathbb{R}$ es probabilidad.
 
**** Función de distribución en un paso
La definimos como: $F(y/x) = P[X_1 \le y / X_0=x]$
**** Distribuciones absolutas del proceso
Las definimos como: $P^{(n)} (B) = P[X_n \in B], \quad \forall B \in \mathcal{B}_E$
**** Distribución del proceso
En el caso de procesos de Markov, la distribución viene determinada por la función de transición en un paso $p(x,B)$ y por $P^{(0)}(B)$ para todo $B\in \mathcal{B}_E$
**** Función de transición en n pasos
Llamamos probabilidad de transición en $n$ pasos a:

\[P[X_{n+m} \in B /X_m = x] = P[X_n\in B / X_0=x] := p_n(x,B) \quad \forall B\in \mathcal{B}_E, \forall n,m \in \mathbb{N}\]

Donde la primera igualdad se deduce de la ecuación de Chapman-Kolmogorov.
**** Función de distribución en $n$ pasos
La definimos como: $F_n(y/x) = P[X_{n} \le y / X_0=x]$

***** Propiedades de la función de transición en $n$ pasos
1. Expresión recursiva: $p_n(x,B) = \int_E p_{n-1} (y,B) P(x,dy)$
2. $P^{(n)}(B) = \int_E p_n(x,B) P^{(0)}(dx) = \int_E p(x,B) P^{(n-1)}(dx)$
3. $P[X_{n_i}\in B_i, i=1, \ldots k] = \int_{B_1} P^{(n_1)} (dx_1) \cdot \int_{B_2} p_{n_2-n_1} (x_1, dx_2) \cdot \int_{B_{k-1}} p_{n_{k-1} - n_{k-2}} (x_{k-2}, dx_{k-1})$

**** Distribución estacionaria y distribución límite
#+begin_definition
- Una distribución $\Pi$ es estacionaria frente a $p(x,B) \Leftrightarrow \forall B\in \mathcal{B}_E \Pi(B) = \int_E p(x,B) \Pi(dx)$
- Una función de distribución $G$ es estacionaria frente a $F(y/x) \Leftrightarrow \forall y\in \mathbb{R} G(y) = \int_E F(y/x) dG(x)$
- $\Pi$ es distribución límite sii $\Pi(B) = lim_{n} P^{(n)}(B) \quad \forall B \in \mathcal{B}_E$
#+end_definition

#+begin_fact
1. Si existe una distribución límite $\Pi$ para el proceso, entonces $\Pi$ es estacionaria.
2. Si $P^{(0)}$ es estacionaria entonces $P^{(n)}$ es estacionaria para todo $n\in \mathbb{N}$
#+end_fact

** Procesos de Markov en tiempo continuo
#+begin_definition
Sea $(\Omega, \mathcal{A}, P)$ espacio probabilístico, $T=[0, +\infty[$, $(E,\mathcal{B}_E)$ con $E\subseteq \mathbb{R}$ espacio de estados, $\{X_t\}_{t\ge 0}$ PETC y $\{\mathcal{F}_t\}$ filtración. Decimos que $\{X_t\}_{t\ge 0}$ es proceso de Markov respecto a $\{\mathcal{F}_t\}$ si:

1. $\forall t\ge 0$ $X_t$ es $\mathcal{F}_t$ medible (adaptado a la filtración.
2. $\forall s < t, \forall B \in \mathcal{B}_E$ se tiene $P[X_t \in B/ \mathcal{F}_s] = P[X_t \in B/X_s]$
#+end_definition

#+begin_fact
*Caracterización de proceso de Markov respecto a filtración arbitraria*

$\{X_t\}$ es PETC respecto de $\{\mathcal{F}_t\}$ sii $\forall f:(E, \mathcal{B}_E) \rightarrow (\mathbb{R}, \mathcal{B})$ medible y acotada se tiene:

\[E[f(X_t) / X_s] = E[f(X_t) / X_s]\]
#+end_fact

#+begin_fact
Sean $\{\mathcal{F}_t^{(i)}\}_{t\ge 0}$ $i=1,2$ dos filtraciones tales que $\mathcal{F}^{(1)} \subseteq \mathcal{F}^{(2)}$. 
Sea $\{X_t\}$ PM respecto $\{F_t^{(2)}\}$ y adaptado a $\{F_t^{(1)}\}$. Entonces es PM respecto a $\{F_t^{(1)}\}$
#+end_fact

#+begin_definition
Se define la *filtración natural* para un PETC $\{X_t\}$ como la menor filtración que hace al proceso adaptado a ella, esto es:

\[\sigma_t = \sigma(X_s, s\le t), \quad t\ge 0\]
#+end_definition

#+begin_definition
$\{X_t\}$ es PM (respecto de la filtración natural) si $\forall s < t, B\in \mathcal{B}_E$ se tiene $P[X_t \in B/X_u, u\le s] = P[X_t \in B/ X_s]$
#+end_definition


#+begin_fact
*Caracterización de proceso de Markov*

Dado $\{X_t\}$ PETC. Equivalen:

1. $\{X_t\}$ es proceso de Markov.
2. $\forall f:(E, \mathcal{B}_E) \rightarrow (\mathbb{R}, \mathcal{B})$ medible y acotada, $\forall s<t$ se tiene: $E[f(X_t)/ X_u, u\le s] = E[f(X_t)/X_s]$
3. $\forall 0\le t_1 < \ldots < t_k < t$, $\forall B\in \mathcal{B}_E$ se tiene $P[X_t \in B/X_{t_1}, \ldots X_{t_k}] = P[X_t \in B/X_{t_k}]$
4. $\forall 0\le t_1 < \ldots < t_k < t$, $\forall B\in \mathcal{B}_E$, $\forall f:(E, \mathcal{B}_E) \rightarrow (\mathbb{R}, \mathcal{B})$ medible y acotada se tiene $P[X_t \in B/X_{t_1}, \ldots X_{t_k}] = P[X_t \in B/X_{t_k}]$
#+end_fact

#+begin_fact
Si $\{X_t\}$ es PM respecto de una filtración arbitraria $\{\mathcal{F}_t\}$ entonces es PM (respecto de la filtración natural.
#+end_fact


#+begin_fact
*Ecuación de Chapman-Kolmogorov*

Sea $\{X_t\}$ proceso de Markov. Entonces $\forall s <u \le t, \forall x\in E, \forall B\in \mathcal{B}_E$. Entonces:

\[P[X_t \in B/X_s = x] = \int_E P[X_t \in B/X_u = y] P[X_u \in dy/X_s = x]\]
#+end_fact


*** Función de transición
La definimos como $P(s,x,t,B) = P[X_t \in B/X_s = x]$ para todo $s\le t, B\in \mathcal{B}_E, x\in E$

**** Propiedades de la función de transición
1. $P(s,x,t, \cdot): \mathcal{B}_E \rightarrow \mathbb{R}$ es probabilidad
2. $P(s,\cdot,t,\mathcal{B}): (E, \mathcal{B}_E) \rightarrow (\mathbb{R}, \mathcal{B})$
3. $\forall B\in \mathcal{B}_E, \forall x\in E, \forall s<u<t$ se tiene $P(s,x,t,B) = \int_E P(u,y,t,B) P(s,x,u,dy)$
4. $P(s,x,s,E-\{x\}) = 0$
*** Función de transición en $n$ pasos
Viene dada por $p_n(x,B):= P[X_{n+m} \in B /X_m = x] = P[X_n \in B/X_0 = x]$ para $x\in E, B\in \mathbb{B}_E$

A partir de ella se define la *función de distribución en $n$ pasos* como:

\[F_n(y/x) = p_n(x, ]-\infty, y])\]
*** Proceso de Markov homogéneo
Un proceso de Markov es homogéneo cuando:

\[P[X_t \in B/X_s=x] = P[X_{t+h} \in B/X_{s+h} = x] = P[X_{t-s}\in B/X_0=x], \quad \forall B\in\mathcal{B}_E; x\in E\; t,s\le 0\]
*** Distribuciones estacionarias y límite
#+begin_definition
1. $\Pi$ es estacionaria frente a $p(x,B) sii $\forall B\in \mathbb{B}_E$ se tiene $\Pi(B) = \int_E p(x,B) \Pi(dx)$
2. $G$ función de distribución es estacionaria frente a $F(y/x)$ sii $\forall y \in\mathbb{R}$ se tiene $G(y) = \int_E F(y/x) dG(x)$
3. $\Pi$ es distribución límite sii $\Pi(B)$ = lim_n P^{(n)}(B), \forall B\in \mathbb{B}_E$
#+end_definition

#+begin_fact
1. Si una distribución $\Pi$ es límite, entonces es estacionaria
2. Si $P^{(0)}$ es estacionaria, entonces $P^{(n)}$ es estacionaria para cualquier $n\in\mathbb{N}$
#+end_fact
* Ejercicios
** Imagen inversa y sigma álgebras
#+begin_wording
Dada $f:X \rightarrow Y$ y $\mathcal{D}$ una $\sigma$ álgebra definida sobre $Y$. Entonces $f^{-1}(\mathcal{D})$ es $\sigma$ álgebra.
#+end_wording

LLamamos $\widehat{\mathcal{D}} = f^{-1}(\mathcal{D})$:

La demostración es trivial sin más que asegurar que dados $\{A_n\}_{n\in\mathbb{N}} = \{f^{-1}(B_n)\}_{n\in\mathbb{N}} \subseteq \widehat{\mathcal{D}}$, donde $B_n \in \mathcal{D}$ tenemos $\cup_{n\in \mathbb{N}} = f^{-1}(\cup_{n\in\mathbb{N}} B_n)$ con $\cup_{n\in\mathbb{N}} B_n \in \mathcal{D}$.

Además dado $A = f^{-1}(B) \in \widehat{\mathcal{D}}, B\in \mathcal{D}$, se tiene $A^c = f^{-1}(B^c)$.

Luego es cerrada para uniones y complementarios.
** Imagen inversa y sigma álgebras generadas por un conjunto
#+begin_wording
Dada $f:X \rightarrow Y$ y $\mathcal{D} = \sigma (W)$ una $\sigma$ álgebra definida sobre $Y$. Entonces $f^{-1}(\mathcal{D}) = \sigma (f^{-1}(W))$
#+end_wording


Claramente $f^{-1}(W) \subseteq f^{-1}(\sigma(W))$, luego tomando $\sigma$ álgebras en ambos miembros, $\sigma(f^{-1}(W)) \subseteq f^{-1}(\sigma(W))$.

Claramente $f^{-1}(W) \in \sigma(f^{-1}(W)) = \mathcal{F}$. Tomo:

\[\mathcal{J} = \{ A\subseteq Y : f^{-1}(A) \in \mathcal{F}\}\]

$W \subseteq \mathcal{J}$ claramente y $\mathcal{J}$ es $\sigma$ álgebra por tenerse que la $f^{-1}$ funciona bien para complementarios y para uniones. Luego $\sigma(W) \subseteq \mathcal{J}$ y eso acaba la demostración.
